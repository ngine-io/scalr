{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Scalr - Autoscaling for Clouds","text":"<p>Scalr allows to scale Cloud instances based on policy checks in a configurable interval. Scalr has 2 pluggable interfaces: cloud, policy.</p>"},{"location":"#cloud-adapters","title":"Cloud Adapters","text":"<p>This is the connector to the API of your Cloud provider. It reads current available servers of your Scalr group and scales up and down based on a calculation factor received from one or more policies:</p> <ul> <li>cloudscale.ch</li> <li>Hetzner Cloud</li> <li>DigitalOcean</li> <li>Apache CloudStack</li> <li>Exoscale</li> <li>Vultr</li> </ul>"},{"location":"#policy-adapters","title":"Policy Adapters","text":"<p>A policy defines check of a target value (amount of CPU, amount of HTTP requests, etc) and where to gather the metric from, such as the following. </p> <p>Note</p> <p>Multiple policies can be used in a single config.</p> <ul> <li>Prometheus</li> <li>HTTP endpoint returning JSON</li> <li>Random metric (for testing)</li> </ul>"},{"location":"#config-interfaces","title":"Config Interfaces","text":"<p>Your Cloud and policy configuration are defined by a configuration. Scalr reads its configuration on every run and can be changed inbetween runs.</p> <ul> <li>Static YAML file (see a sample)</li> </ul>"},{"location":"cloud/","title":"Cloud configs","text":"<p>Cloud config to be used for lunching new instances.</p> <p>Warning</p> <p>Changing a cloud launch config have no affect to already running cloud instances. But this may change in the future.</p>"},{"location":"cloud/#cloudscalech","title":"cloudscale.ch","text":"<pre><code>cloud:\nkind: cloudscale_ch\nlaunch_config:\nflavor: flex-2\nimage: debian-10\nzone: lpg1\ntags:\nproject: gemini\nssh_keys:\n- ssh-rsa AAAA...\nuser_data: |\n#cloud-config\nmanage_etc_hosts: true\npackage_update: true\npackage_upgrade: true\npackages:\n- nginx\n</code></pre>"},{"location":"cloud/#apache-cloudstack","title":"Apache CloudStack","text":"<pre><code>cloud:\nkind: cloudstack\nlaunch_config:\nservice_offering: Micro\ntemplate: Linux Debian 10\nzone: de-xy-1\nssh_key: my-key\ntags:\nproject: gemini\nroot_disk_size: 20\nuser_data: |\n#cloud-config\nmanage_etc_hosts: true\npackage_update: true\npackage_upgrade: true\npackages:\n- nginx\n</code></pre>"},{"location":"cloud/#digitalocean","title":"DigitalOcean","text":"<pre><code>cloud:\nkind: digitalocean\nlaunch_config:\nsize: s-1vcpu-1gb\nimage: debian-10-x64\nregion: ams3\nssh_keys:\n- 'b5:be:e8:...'\ntags:\n- 'project:gemini'\nuser_data: |\n#cloud-config\nmanage_etc_hosts: true\npackage_update: true\npackage_upgrade: true\npackages:\n- nginx\n</code></pre>"},{"location":"cloud/#hetzner-cloud","title":"Hetzner Cloud","text":"<pre><code>cloud:\nkind: hcloud\nlaunch_config:\nserver_type: cx11\nimage: debian-10\nlabels:\nproject: gemini\nlocation: fsn1\nssh_keys:\n- my_key\nuser_data: |\n#cloud-config\nmanage_etc_hosts: true\npackage_update: true\npackage_upgrade: true\npackages:\n- nginx\n</code></pre>"},{"location":"cloud/#vultr-cloud","title":"Vultr Cloud","text":"<pre><code>cloud:\nkind: vultr\nlaunch_config:\nplan: vc2-1c-1gb\n# Debian 11\nos_id: 477\nregion: fra\nsshkey_id:\n- xxxxxxxx-...\nuser_data: |\n#!/bin/sh\necho \"Hello World\" &gt; /root/hello-world.txt\n# script_id: ...\n# iso_id: ...\n# snapshot_id ...\n# enable_ipv6: true\n# backups: enabled\n# app_id: app_id\n# image_id: image_id\n# activation_email: true\n# attach_private_network: [...]\n# app_id: ...\n# image_id: ...\n# ddos_protection: true\n# firewall_group_id: ...\n# enable_private_network: true\n</code></pre>"},{"location":"cloud/#apache-cloudstack_1","title":"Apache CloudStack","text":"<pre><code>  kind: cloudstack\nlaunch_config:\nservice_offering: cpu2-ram2\ntemplate: Linux Template xyz\nzone: my-zone\nssh_key: my_ssh_key\ntags:\nproject: gemini\nroot_disk_size: 20\nuser_data: |\n#cloud-config\nmanage_etc_hosts: true\npackages:\n- nginx\n</code></pre>"},{"location":"cloud/#exoscale","title":"Exoscale","text":"<pre><code>  kind: exoscale\nlaunch_config:\nservice_offering: Micro\ntemplate: Linux Debian 11 (Bullseye) 64-bit\nzone: ch-dk-2\nssh_key: my-ssh-key\nuse_ipv6: true\ntags:\nproject: gemini\nroot_disk_size: 20\nuser_data: |\n#cloud-config\nmanage_etc_hosts: true\npackages:\n- nginx\n</code></pre>"},{"location":"config/","title":"Configs","text":"<p>Scale configuration is made by creating a <code>config.yml</code> or whatever file <code>SCALR_CONFIG</code> points to.</p> <p>Hint</p> <p>The config will be re-read before every run, no need to restart a running Scalr service after a config change.</p>"},{"location":"config/#common-config-skeleton","title":"Common Config Skeleton","text":"<p>Hint</p> <p>You find a sample config.yml in our GitHub Repo</p> <pre><code>---\n# Name is used to group instances e.g. with a tag or label depending on the cloud provider\n# NOTE: If you change the name, all current instances having the name are getting unmanaged.\nname: my-app\n# Change it to false to completely skip all action\nenabled: true\n# Change it to false to skip the scaling\ndry_run: false\n# Not scaling down below this value\nmin: 2\n# Not scaling up above this value\nmax: 5\n# The max value of instances to be scaled down in one run\nmax_step_down: 1\n# Strategy of order to destroy instances\nscale_down_selection: oldest\n# After scaling down, wait for so long in seconds\ncooldown_timeout: 60\n# See Policy configs\npolicies: []\n# See cloud config\ncloud:\nkind: ...\nlaunch_config: {}\n</code></pre>"},{"location":"install/","title":"Install and base settings","text":""},{"location":"install/#install","title":"Install","text":"<p>Warning</p> <p>Scalr is in beta.</p> <pre><code>pip install scalr-ngine\n</code></pre>"},{"location":"install/#settings","title":"Settings","text":"<p>Settings can be set either by ENV vars or by providing a <code>.env</code> file:</p>"},{"location":"install/#common-env-variables","title":"Common ENV variables","text":"<pre><code>SCALR_LOG_LEVEL=INFO\nSCALR_CONFIG=./config.yml\n</code></pre>"},{"location":"install/#cloud-env-variables","title":"Cloud ENV variables","text":""},{"location":"install/#cloudscalech-api-token","title":"Cloudscale.ch API token","text":"<pre><code>CLOUDSCALE_API_TOKEN=&lt;...&gt;\n</code></pre>"},{"location":"install/#cloudstack-api-settings","title":"CloudStack API settings","text":"<pre><code>CLOUDSTACK_API_ENDPOINT=https://cloud.example.com/client/api\nCLOUDSTACK_API_KEY=&lt;...&gt;\nCLOUDSTACK_API_SECRET=&lt;...&gt;\n</code></pre>"},{"location":"install/#digitalocean-api-access-token","title":"DigitalOcean API access token","text":"<pre><code>DIGITALOCEAN_ACCESS_TOKEN=&lt;...&gt;\n</code></pre>"},{"location":"install/#exoscale-api-settings","title":"Exoscale API settings","text":"<pre><code>EXOSCALE_API_KEY=&lt;...&gt;\nEXOSCALE_API_SECRET=&lt;...&gt;\n</code></pre>"},{"location":"install/#hetzner-cloud-api-token","title":"Hetzner Cloud API token","text":"<pre><code>HCLOUD_API_TOKEN=&lt;...&gt;\n</code></pre>"},{"location":"install/#vultr-api-key","title":"Vultr API key","text":"<pre><code>VULTR_API_KEY=&lt;...&gt;\n</code></pre>"},{"location":"policy_configs/","title":"Policy Configs","text":"<p>Policies define if and how much to scale.</p>"},{"location":"policy_configs/#metric-target","title":"Metric Target","text":"<p>The target in is the metric we want to reach. A source metric returned higher than this target will result in scaling up, a lower to scaling down.</p> <p>Example</p> <p>Given a target of 5, a source metric returned of 10 will results in a scaling factor 2.0. With 2 instances already running, a factor 2 will scale to 4 instances (2 x 2.0), except the max allow instances is lower than 4.</p>"},{"location":"policy_configs/#prometheus-policy","title":"Prometheus Policy","text":"<p>Query a Prometheus endpoint.</p> <pre><code>policy:\n- name: CPU avg load &lt; 60%\ntarget: 60\nsource: prometheus\nconfig:\nurl: http://prometheus.example.com:9090\nquery: '100 - (avg by (job) (rate(node_cpu_seconds_total{mode=\"idle\", instance=~\"cluster-node.*\"}[10m])) * 100)'\n</code></pre>"},{"location":"policy_configs/#web-policy","title":"Web Policy","text":"<p>Query a web endpoint.</p> <p>A JSON return <code>{\"metric\": &lt;int&gt;}</code> is expected in this case.</p> <pre><code>policy:\n- name: get metric from web\nsource: web\nquery: http://localhost:8000/target.json\nconfig:\n# Optional headers\nheaders:\nAuthorization: Bearer xyz\n# Optional default key 'data'\nkey: metric\ntarget: 5\n</code></pre>"},{"location":"policy_configs/#time-policy","title":"Time Policy","text":"<p>Time based scaling, scaling during time ranges.</p> <pre><code>policy:\n- name: Scaling up at 7 a.m. by factor 2 (pre-heating for known load)\nsource: time\ntarget: 2\nconfig:\nstart_time: \"06:58\"\nend_time: \"07:00\"\nmetric: 1\n</code></pre> <pre><code>policy:\n- name: Scaling down during night\nsource: time\ntarget: 1\nconfig:\nstart_time: \"22:00\"\nend_time: \"05:00\"\nmetric: 10\n</code></pre>"},{"location":"policy_configs/#random-policy","title":"Random Policy","text":"<p>For testing purpose, random metric to get some action.</p> <pre><code>policy:\n- name: get random nonsense\nsource: random\ntarget: 3\nconfig:\nstart: 1\nstop: 10\n</code></pre>"},{"location":"running/","title":"Running","text":""},{"location":"running/#start-scalr","title":"Start Scalr","text":"<p>As \"one shot\" meant to be used as cron job execution:</p> <p>Note</p> <p>One shot execution does not provide Prometheus metrics.</p> <pre><code>scalr-ngine\n</code></pre> <p>As daemon:</p> <pre><code>export SCALR_INTERVAL=20\nscalr-ngine --periodic\n</code></pre>"},{"location":"running/#docker","title":"Docker","text":"<p>We provide docker images as <code>registry.gitlab.com/ngine/docker-images/scalr:latest</code>.</p> <p>A minimal docker compose file would look like:</p> <pre><code>---\nversion: \"3.9\"\nservices:\nscalr:\nimage: registry.gitlab.com/ngine/docker-images/scalr:latest\nports:\n- \"8000:8000\"\ncommand: --periodic\nenvironment:\n- SCALR_INTERVAL=60\n- SCALR_LOG_LEVEL=INFO\n- SCALR_CONFIG=/app/config.yml\n- SCALR_PROMETHEUS_EXPORTER_PORT=8000\n- VULTR_API_KEY=...\nvolumes:\n- \"./config.yml:/app/config.yml:ro\"\n</code></pre>"},{"location":"running/#monitoring","title":"Monitoring","text":"<p>Hint</p> <p>Exporter port can be changed <code>SCALR_PROMETHEUS_EXPORTER_PORT</code>. Default is 8000.</p> <p>Scalr running in <code>--periodic</code> exports Prometheus metrics, such as:</p> <pre><code># HELP python_gc_objects_collected_total Objects collected during gc\n# TYPE python_gc_objects_collected_total counter\npython_gc_objects_collected_total{generation=\"0\"} 37145.0\npython_gc_objects_collected_total{generation=\"1\"} 6512.0\npython_gc_objects_collected_total{generation=\"2\"} 687.0\n# HELP python_gc_objects_uncollectable_total Uncollectable object found during GC\n# TYPE python_gc_objects_uncollectable_total counter\npython_gc_objects_uncollectable_total{generation=\"0\"} 0.0\npython_gc_objects_uncollectable_total{generation=\"1\"} 0.0\npython_gc_objects_uncollectable_total{generation=\"2\"} 0.0\n# HELP python_gc_collections_total Number of times this generation was collected\n# TYPE python_gc_collections_total counter\npython_gc_collections_total{generation=\"0\"} 234.0\npython_gc_collections_total{generation=\"1\"} 21.0\npython_gc_collections_total{generation=\"2\"} 1.0\n# HELP python_info Python platform information\n# TYPE python_info gauge\npython_info{implementation=\"CPython\",major=\"3\",minor=\"8\",patchlevel=\"10\",version=\"3.8.10\"} 1.0\n# HELP process_virtual_memory_bytes Virtual memory size in bytes.\n# TYPE process_virtual_memory_bytes gauge\nprocess_virtual_memory_bytes 6.71674368e+08\n# HELP process_resident_memory_bytes Resident memory size in bytes.\n# TYPE process_resident_memory_bytes gauge\nprocess_resident_memory_bytes 8.3685376e+07\n# HELP process_start_time_seconds Start time of the process since unix epoch in seconds.\n# TYPE process_start_time_seconds gauge\nprocess_start_time_seconds 1.64899542198e+09\n# HELP process_cpu_seconds_total Total user and system CPU time spent in seconds.\n# TYPE process_cpu_seconds_total counter\nprocess_cpu_seconds_total 157.28\n# HELP process_open_fds Number of open file descriptors.\n# TYPE process_open_fds gauge\nprocess_open_fds 32.0\n# HELP process_max_fds Maximum number of open file descriptors.\n# TYPE process_max_fds gauge\nprocess_max_fds 8192.0\n# HELP scalr_min Min amount of resources\n# TYPE scalr_min gauge\nscalr_min 1.0\n# HELP scalr_max Max amount of resources\n# TYPE scalr_max gauge\nscalr_max 5.0\n# HELP scalr_factor Calculated factor of policies\n# TYPE scalr_factor gauge\nscalr_factor 5.0\n# HELP scalr_desired Desired amount of resources\n# TYPE scalr_desired gauge\nscalr_desired 5.0\n# HELP scalr_current Current amount of resources\n# TYPE scalr_current gauge\nscalr_current 5.0\n# HELP scalr_max_step_down Max step for scaling down\n# TYPE scalr_max_step_down gauge\nscalr_max_step_down 1.0\n# HELP scalr_cooldown_timeout Timeout in seconds after scaling actions\n# TYPE scalr_cooldown_timeout gauge\nscalr_cooldown_timeout 300.0\n# HELP scalr_dry_run Dry run mode\n# TYPE scalr_dry_run gauge\nscalr_dry_run{scalr_dry_run=\"on\"} 0.0\nscalr_dry_run{scalr_dry_run=\"off\"} 1.0\n# HELP scalr_enabled Scaling enabled\n# TYPE scalr_enabled gauge\nscalr_enabled{scalr_enabled=\"yes\"} 1.0\nscalr_enabled{scalr_enabled=\"no\"} 0.0\n</code></pre>"},{"location":"running/#prometheus-scrape-config","title":"Prometheus Scrape Config","text":"<pre><code>scrape_configs:\n- job_name: scalr\nmetrics_path: /\nscrape_interval: 5s\nstatic_configs:\n- targets:\n- scalr-app:8000\n</code></pre>"},{"location":"running/#grafana-dashboard","title":"Grafana Dashboard","text":"<p>A simple dashboard for scalr can be found on Github</p> <p></p>"}]}