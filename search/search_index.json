{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Scalr - Autoscaling for Clouds","text":"<p>Scalr allows to scale Cloud instances based on policy checks in a configurable interval. Scalr has 2 pluggable interfaces: cloud, policy.</p>"},{"location":"#cloud-adapters","title":"Cloud Adapters","text":"<p>This is the connector to the API of your Cloud provider. It reads current available servers of your Scalr group and scales up and down based on a calculation factor received from one or more policies:</p> <ul> <li>cloudscale.ch</li> <li>Hetzner Cloud</li> <li>DigitalOcean</li> <li>Apache CloudStack</li> <li>Vultr</li> </ul>"},{"location":"#policy-adapters","title":"Policy Adapters","text":"<p>A policy defines check of a target value (amount of CPU, amount of HTTP requests, etc) and where to gather the metric from, such as the following.</p> <p>Note</p> <p>Multiple policies can be used in a single config.</p> <ul> <li>Prometheus</li> <li>Time Policy</li> <li>HTTP endpoint returning JSON</li> <li>Random metric (for testing)</li> </ul>"},{"location":"#config-interfaces","title":"Config Interfaces","text":"<p>Your Cloud and policy configuration are defined by a configuration. Scalr reads its configuration on every run and can be changed inbetween runs.</p> <ul> <li>Static YAML file (see a sample)</li> </ul>"},{"location":"cloud/","title":"Cloud configs","text":"<p>Cloud config to be used for lunching new instances.</p> <p>Warning</p> <p>Changing a cloud launch config have no affect to already running cloud instances. But this may change in the future.</p>"},{"location":"cloud/#cloudscalech","title":"cloudscale.ch","text":"<pre><code>cloud:\n  kind: cloudscale_ch\n  launch_config:\n    flavor: flex-2\n    image: debian-10\n    zone: lpg1\n    tags:\n      project: gemini\n    ssh_keys:\n      - ssh-rsa AAAA...\n    user_data: |\n      #cloud-config\n      manage_etc_hosts: true\n      package_update: true\n      package_upgrade: true\n      packages:\n        - nginx\n</code></pre>"},{"location":"cloud/#apache-cloudstack","title":"Apache CloudStack","text":"<pre><code>cloud:\n  kind: cloudstack\n  launch_config:\n    service_offering: Micro\n    template: Linux Debian 10\n    zone: de-xy-1\n    ssh_key: my-key\n    tags:\n      project: gemini\n    root_disk_size: 20\n    user_data: |\n      #cloud-config\n      manage_etc_hosts: true\n      package_update: true\n      package_upgrade: true\n      packages:\n        - nginx\n</code></pre>"},{"location":"cloud/#digitalocean","title":"DigitalOcean","text":"<pre><code>cloud:\n  kind: digitalocean\n  launch_config:\n    size: s-1vcpu-1gb\n    image: debian-10-x64\n    region: ams3\n    ssh_keys:\n      - 'b5:be:e8:...'\n    tags:\n      - 'project:gemini'\n    user_data: |\n      #cloud-config\n      manage_etc_hosts: true\n      package_update: true\n      package_upgrade: true\n      packages:\n        - nginx\n</code></pre>"},{"location":"cloud/#hetzner-cloud","title":"Hetzner Cloud","text":"<pre><code>cloud:\n  kind: hcloud\n  launch_config:\n    server_type: cx11\n    image: debian-10\n    labels:\n      project: gemini\n    location: fsn1\n    ssh_keys:\n      - my_key\n    user_data: |\n      #cloud-config\n      manage_etc_hosts: true\n      package_update: true\n      package_upgrade: true\n      packages:\n        - nginx\n</code></pre>"},{"location":"cloud/#vultr-cloud","title":"Vultr Cloud","text":"<pre><code>cloud:\n  kind: vultr\n  launch_config:\n    plan: vc2-1c-1gb\n    # Debian 11\n    os_id: 477\n    region: fra\n    sshkey_id:\n      - xxxxxxxx-...\n    user_data: |\n      #!/bin/sh\n      echo \"Hello World\" &gt; /root/hello-world.txt\n    # script_id: ...\n    # iso_id: ...\n    # snapshot_id ...\n    # enable_ipv6: true\n    # backups: enabled\n    # app_id: app_id\n    # image_id: image_id\n    # activation_email: true\n    # attach_private_network: [...]\n    # app_id: ...\n    # image_id: ...\n    # ddos_protection: true\n    # firewall_group_id: ...\n    # enable_private_network: true\n</code></pre>"},{"location":"cloud/#apache-cloudstack_1","title":"Apache CloudStack","text":"<pre><code>  kind: cloudstack\n  launch_config:\n    service_offering: cpu2-ram2\n    template: Linux Template xyz\n    zone: my-zone\n    ssh_key: my_ssh_key\n    tags:\n      project: gemini\n    root_disk_size: 20\n    user_data: |\n      #cloud-config\n      manage_etc_hosts: true\n      packages:\n        - nginx\n</code></pre>"},{"location":"config/","title":"Configs","text":"<p>Scale configuration is made by creating a <code>config.yml</code> or whatever file <code>SCALR_CONFIG</code> points to.</p> <p>Hint</p> <p>The config will be re-read before every run, no need to restart a running Scalr service after a config change.</p>"},{"location":"config/#common-config-skeleton","title":"Common Config Skeleton","text":"<p>Hint</p> <p>You find a sample config.yml in our GitHub Repo</p> <pre><code>---\n# Name is used to group instances e.g. with a tag or label depending on the cloud provider\n# NOTE: If you change the name, all current instances having the name are getting unmanaged.\nname: my-app\n\n# Change it to false to completely skip all action\nenabled: true\n\n# Change it to false to skip the scaling\ndry_run: false\n\n# Not scaling down below this value\nmin: 2\n\n# Not scaling up above this value\nmax: 5\n\n# The max value of instances to be scaled down in one run\nmax_step_down: 1\n\n# Strategy of order to destroy instances\nscale_down_selection: oldest\n\n# After scaling down, wait for so long in seconds\ncooldown_timeout: 60\n\n# See Policy configs\npolicies: []\n\n# See cloud config\ncloud:\n  kind: ...\n  launch_config: {}\n</code></pre>"},{"location":"install/","title":"Install and base settings","text":""},{"location":"install/#install","title":"Install","text":"<p>Warning</p> <p>Scalr is in beta.</p> <pre><code>pip install scalr-ngine\n</code></pre>"},{"location":"install/#settings","title":"Settings","text":"<p>Settings can be set either by ENV vars or by providing a <code>.env</code> file:</p>"},{"location":"install/#common-env-variables","title":"Common ENV variables","text":"<pre><code>SCALR_LOG_LEVEL=INFO\nSCALR_CONFIG=./config.yml\n</code></pre>"},{"location":"install/#cloud-env-variables","title":"Cloud ENV variables","text":""},{"location":"install/#cloudscalech-api-token","title":"Cloudscale.ch API token","text":"<pre><code>CLOUDSCALE_API_TOKEN=&lt;...&gt;\n</code></pre>"},{"location":"install/#cloudstack-api-settings","title":"CloudStack API settings","text":"<pre><code>CLOUDSTACK_API_ENDPOINT=https://cloud.example.com/client/api\nCLOUDSTACK_API_KEY=&lt;...&gt;\nCLOUDSTACK_API_SECRET=&lt;...&gt;\n</code></pre>"},{"location":"install/#digitalocean-api-access-token","title":"DigitalOcean API access token","text":"<pre><code>DIGITALOCEAN_ACCESS_TOKEN=&lt;...&gt;\n</code></pre>"},{"location":"install/#hetzner-cloud-api-token","title":"Hetzner Cloud API token","text":"<pre><code>HCLOUD_API_TOKEN=&lt;...&gt;\n</code></pre>"},{"location":"install/#vultr-api-key","title":"Vultr API key","text":"<pre><code>VULTR_API_KEY=&lt;...&gt;\n</code></pre>"},{"location":"policy_configs/","title":"Policy Configs","text":"<p>Policies define if and how much to scale.</p>"},{"location":"policy_configs/#metric-target","title":"Metric Target","text":"<p>The target in is the metric we want to reach. A source metric returned higher than this target will result in scaling up, a lower to scaling down.</p> <p>Example</p> <p>Given a target of 5, a source metric returned of 10 will results in a scaling factor 2.0. With 2 instances already running, a factor 2 will scale to 4 instances (2 x 2.0), except the max allow instances is lower than 4.</p>"},{"location":"policy_configs/#prometheus-policy","title":"Prometheus Policy","text":"<p>Query a Prometheus endpoint.</p> <pre><code>policy:\n- name: CPU avg load &lt; 60%\n  target: 60\n  source: prometheus\n  config:\n    url: http://prometheus.example.com:9090\n    query: '100 - (avg by (job) (rate(node_cpu_seconds_total{mode=\"idle\", instance=~\"cluster-node.*\"}[10m])) * 100)'\n</code></pre>"},{"location":"policy_configs/#web-policy","title":"Web Policy","text":"<p>Query a web endpoint.</p> <p>A JSON return <code>{\"metric\": &lt;int&gt;}</code> is expected in this case.</p> <pre><code>policy:\n- name: get metric from web\n  source: web\n  query: http://localhost:8000/target.json\n  config:\n    # Optional headers\n    headers:\n      Authorization: Bearer xyz\n    # Optional default key 'data'\n    key: metric\n  target: 5\n</code></pre>"},{"location":"policy_configs/#time-policy","title":"Time Policy","text":"<p>Time based scaling, scaling during time ranges.</p> <pre><code>policy:\n- name: Scaling up at 7 a.m. by factor 2 (pre-heating for known load)\n  source: time\n  target: 2\n  config:\n    start_time: \"06:58\"\n    end_time: \"07:00\"\n    metric: 1\n</code></pre> <pre><code>policy:\n- name: Scaling down during night\n  source: time\n  target: 1\n  config:\n    start_time: \"22:00\"\n    end_time: \"05:00\"\n    metric: 10\n</code></pre>"},{"location":"policy_configs/#random-policy","title":"Random Policy","text":"<p>For testing purpose, random metric to get some action.</p> <pre><code>policy:\n- name: get random nonsense\n  source: random\n  target: 3\n  config:\n    start: 1\n    stop: 10\n</code></pre>"},{"location":"running/","title":"Running","text":""},{"location":"running/#start-scalr","title":"Start Scalr","text":"<p>As \"one shot\" meant to be used as cron job execution:</p> <p>Note</p> <p>One shot execution does not provide Prometheus metrics.</p> <pre><code>scalr-ngine\n</code></pre> <p>As daemon:</p> <pre><code>export SCALR_INTERVAL=20\nscalr-ngine --periodic\n</code></pre>"},{"location":"running/#docker","title":"Docker","text":"<p>We provide docker images as <code>ghcr.io/ngine-io/scalr:latest</code>.</p> <p>A minimal docker compose file would look like:</p> <pre><code>---\nversion: \"3.9\"\nservices:\n  scalr:\n    image: ghcr.io/ngine-io/scalr:latest\n    ports:\n      - \"8000:8000\"\n    command: --periodic\n    environment:\n      - SCALR_INTERVAL=60\n      - SCALR_LOG_LEVEL=INFO\n      - SCALR_CONFIG=/app/config.yml\n      - SCALR_PROMETHEUS_EXPORTER_PORT=8000\n      - VULTR_API_KEY=...\n    volumes:\n      - \"./config.yml:/app/config.yml:ro\"\n</code></pre>"},{"location":"running/#monitoring","title":"Monitoring","text":"<p>Hint</p> <p>Exporter port can be changed <code>SCALR_PROMETHEUS_EXPORTER_PORT</code>. Default is 8000.</p> <p>Scalr running in <code>--periodic</code> exports Prometheus metrics, such as:</p> <pre><code># HELP python_gc_objects_collected_total Objects collected during gc\n# TYPE python_gc_objects_collected_total counter\npython_gc_objects_collected_total{generation=\"0\"} 37145.0\npython_gc_objects_collected_total{generation=\"1\"} 6512.0\npython_gc_objects_collected_total{generation=\"2\"} 687.0\n# HELP python_gc_objects_uncollectable_total Uncollectable object found during GC\n# TYPE python_gc_objects_uncollectable_total counter\npython_gc_objects_uncollectable_total{generation=\"0\"} 0.0\npython_gc_objects_uncollectable_total{generation=\"1\"} 0.0\npython_gc_objects_uncollectable_total{generation=\"2\"} 0.0\n# HELP python_gc_collections_total Number of times this generation was collected\n# TYPE python_gc_collections_total counter\npython_gc_collections_total{generation=\"0\"} 234.0\npython_gc_collections_total{generation=\"1\"} 21.0\npython_gc_collections_total{generation=\"2\"} 1.0\n# HELP python_info Python platform information\n# TYPE python_info gauge\npython_info{implementation=\"CPython\",major=\"3\",minor=\"8\",patchlevel=\"10\",version=\"3.8.10\"} 1.0\n# HELP process_virtual_memory_bytes Virtual memory size in bytes.\n# TYPE process_virtual_memory_bytes gauge\nprocess_virtual_memory_bytes 6.71674368e+08\n# HELP process_resident_memory_bytes Resident memory size in bytes.\n# TYPE process_resident_memory_bytes gauge\nprocess_resident_memory_bytes 8.3685376e+07\n# HELP process_start_time_seconds Start time of the process since unix epoch in seconds.\n# TYPE process_start_time_seconds gauge\nprocess_start_time_seconds 1.64899542198e+09\n# HELP process_cpu_seconds_total Total user and system CPU time spent in seconds.\n# TYPE process_cpu_seconds_total counter\nprocess_cpu_seconds_total 157.28\n# HELP process_open_fds Number of open file descriptors.\n# TYPE process_open_fds gauge\nprocess_open_fds 32.0\n# HELP process_max_fds Maximum number of open file descriptors.\n# TYPE process_max_fds gauge\nprocess_max_fds 8192.0\n# HELP scalr_min Min amount of resources\n# TYPE scalr_min gauge\nscalr_min 1.0\n# HELP scalr_max Max amount of resources\n# TYPE scalr_max gauge\nscalr_max 5.0\n# HELP scalr_factor Calculated factor of policies\n# TYPE scalr_factor gauge\nscalr_factor 5.0\n# HELP scalr_desired Desired amount of resources\n# TYPE scalr_desired gauge\nscalr_desired 5.0\n# HELP scalr_current Current amount of resources\n# TYPE scalr_current gauge\nscalr_current 5.0\n# HELP scalr_max_step_down Max step for scaling down\n# TYPE scalr_max_step_down gauge\nscalr_max_step_down 1.0\n# HELP scalr_cooldown_timeout Timeout in seconds after scaling actions\n# TYPE scalr_cooldown_timeout gauge\nscalr_cooldown_timeout 300.0\n# HELP scalr_dry_run Dry run mode\n# TYPE scalr_dry_run gauge\nscalr_dry_run{scalr_dry_run=\"on\"} 0.0\nscalr_dry_run{scalr_dry_run=\"off\"} 1.0\n# HELP scalr_enabled Scaling enabled\n# TYPE scalr_enabled gauge\nscalr_enabled{scalr_enabled=\"yes\"} 1.0\nscalr_enabled{scalr_enabled=\"no\"} 0.0\n</code></pre>"},{"location":"running/#prometheus-scrape-config","title":"Prometheus Scrape Config","text":"<pre><code>scrape_configs:\n- job_name: scalr\n  metrics_path: /\n  scrape_interval: 5s\n  static_configs:\n    - targets:\n      - scalr-app:8000\n</code></pre>"},{"location":"running/#grafana-dashboard","title":"Grafana Dashboard","text":"<p>A simple dashboard for scalr can be found on Github</p> <p></p>"}]}