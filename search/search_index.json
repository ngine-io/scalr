{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Scalr - Autoscaling for Clouds Scalr allows to scale Cloud instances based on policy checks in a configurable interval. Scalr has 2 pluggable interfaces: cloud, policy. Cloud Adapters This is the connector to the API of your Cloud provider. It reads current available servers of your Scalr group and scales up and down based on a calculation factor received from one or more policies: Cloudscale.ch Hetzner Cloud DigitalOcean Apache CloudStack Exoscale Vultr Policy Adapters A policy defines check of a target value (amount of CPU, amount of HTTP requests, etc) and where to gather the metric from, such as the following. Multiple policies can be used in a single config. Prometheus HTTP endpoint returning JSON Random Metric (for testing) Config Interfaces Your Cloud and policy configuration are defined by a configuration. Scalr reads its configuration on every run and can be changed inbetween runs. Static YAML file","title":"Home"},{"location":"#scalr-autoscaling-for-clouds","text":"Scalr allows to scale Cloud instances based on policy checks in a configurable interval. Scalr has 2 pluggable interfaces: cloud, policy.","title":"Scalr - Autoscaling for Clouds"},{"location":"#cloud-adapters","text":"This is the connector to the API of your Cloud provider. It reads current available servers of your Scalr group and scales up and down based on a calculation factor received from one or more policies: Cloudscale.ch Hetzner Cloud DigitalOcean Apache CloudStack Exoscale Vultr","title":"Cloud Adapters"},{"location":"#policy-adapters","text":"A policy defines check of a target value (amount of CPU, amount of HTTP requests, etc) and where to gather the metric from, such as the following. Multiple policies can be used in a single config. Prometheus HTTP endpoint returning JSON Random Metric (for testing)","title":"Policy Adapters"},{"location":"#config-interfaces","text":"Your Cloud and policy configuration are defined by a configuration. Scalr reads its configuration on every run and can be changed inbetween runs. Static YAML file","title":"Config Interfaces"},{"location":"cloud/","text":"Cloud configs Cloud config to be used for lunching new instances. Warning Changing a cloud launch config have no affect to already running cloud instances. But this may change in the future. Cloudscale.ch cloud : kind : cloudscale_ch launch_config : flavor : flex-2 image : debian-10 zone : lpg1 tags : project : gemini ssh_keys : - ssh-rsa AAAA... user_data : | #cloud-config manage_etc_hosts: true package_update: true package_upgrade: true packages: - nginx Apache CloudStack cloud : kind : cloudstack launch_config : service_offering : Micro template : Linux Debian 10 zone : de-xy-1 ssh_key : my-key tags : project : gemini root_disk_size : 20 user_data : | #cloud-config manage_etc_hosts: true package_update: true package_upgrade: true packages: - nginx DigitalOcean cloud : kind : digitalocean launch_config : size : s-1vcpu-1gb image : debian-10-x64 region : ams3 ssh_keys : - 'b5:be:e8:...' tags : - 'project:gemini' user_data : | #cloud-config manage_etc_hosts: true package_update: true package_upgrade: true packages: - nginx Hetzner Cloud cloud : kind : hcloud launch_config : server_type : cx11 image : debian-10 labels : project : gemini location : fsn1 ssh_keys : - my_key user_data : | #cloud-config manage_etc_hosts: true package_update: true package_upgrade: true packages: - nginx Vultr Cloud cloud : kind : vultr launch_config : plan : vc2-1c-1gb # Debian 11 os_id : 477 region : fra sshkey_id : - xxxxxxxx-... user_data : | #!/bin/sh echo \"Hello World\" > /root/hello-world.txt # script_id: ... # iso_id: ... # snapshot_id ... # enable_ipv6: true # backups: enabled # app_id: app_id # image_id: image_id # activation_email: true # attach_private_network: [...] # app_id: ... # image_id: ... # ddos_protection: true # firewall_group_id: ... # enable_private_network: true","title":"Cloud Configs"},{"location":"cloud/#cloud-configs","text":"Cloud config to be used for lunching new instances. Warning Changing a cloud launch config have no affect to already running cloud instances. But this may change in the future.","title":"Cloud configs"},{"location":"cloud/#cloudscalech","text":"cloud : kind : cloudscale_ch launch_config : flavor : flex-2 image : debian-10 zone : lpg1 tags : project : gemini ssh_keys : - ssh-rsa AAAA... user_data : | #cloud-config manage_etc_hosts: true package_update: true package_upgrade: true packages: - nginx","title":"Cloudscale.ch"},{"location":"cloud/#apache-cloudstack","text":"cloud : kind : cloudstack launch_config : service_offering : Micro template : Linux Debian 10 zone : de-xy-1 ssh_key : my-key tags : project : gemini root_disk_size : 20 user_data : | #cloud-config manage_etc_hosts: true package_update: true package_upgrade: true packages: - nginx","title":"Apache CloudStack"},{"location":"cloud/#digitalocean","text":"cloud : kind : digitalocean launch_config : size : s-1vcpu-1gb image : debian-10-x64 region : ams3 ssh_keys : - 'b5:be:e8:...' tags : - 'project:gemini' user_data : | #cloud-config manage_etc_hosts: true package_update: true package_upgrade: true packages: - nginx","title":"DigitalOcean"},{"location":"cloud/#hetzner-cloud","text":"cloud : kind : hcloud launch_config : server_type : cx11 image : debian-10 labels : project : gemini location : fsn1 ssh_keys : - my_key user_data : | #cloud-config manage_etc_hosts: true package_update: true package_upgrade: true packages: - nginx","title":"Hetzner Cloud"},{"location":"cloud/#vultr-cloud","text":"cloud : kind : vultr launch_config : plan : vc2-1c-1gb # Debian 11 os_id : 477 region : fra sshkey_id : - xxxxxxxx-... user_data : | #!/bin/sh echo \"Hello World\" > /root/hello-world.txt # script_id: ... # iso_id: ... # snapshot_id ... # enable_ipv6: true # backups: enabled # app_id: app_id # image_id: image_id # activation_email: true # attach_private_network: [...] # app_id: ... # image_id: ... # ddos_protection: true # firewall_group_id: ... # enable_private_network: true","title":"Vultr Cloud"},{"location":"config/","text":"Configs Scale configuration is made by creating a config.yml or whatever file SCALR_CONFIG points to. Hint The config will be re-read before every run, no need to restart a running Scalr service after a config change. Common Config Skeleton Hint You find a sample config.yml in our GitHub Repo --- # Name is used to group instances e.g. with a tag or label depending on the cloud provider # NOTE: If you change the name, all current instances having the name are getting unmanaged. name : my-app # Change it to false to completely skip all action enabled : true # Change it to false to skip the scaling dry_run : false # Not scaling down below this value min : 2 # Not scaling up above this value max : 5 # The max value of instances to be scaled down in one run max_step_down : 1 # Strategy of order to destroy instances scale_down_selection : oldest # After scaling down, wait for so long in seconds cooldown_timeout : 60 # See Policy configs policies : [] # See cloud config cloud : kind : ... launch_config : {}","title":"Common"},{"location":"config/#configs","text":"Scale configuration is made by creating a config.yml or whatever file SCALR_CONFIG points to. Hint The config will be re-read before every run, no need to restart a running Scalr service after a config change.","title":"Configs"},{"location":"config/#common-config-skeleton","text":"Hint You find a sample config.yml in our GitHub Repo --- # Name is used to group instances e.g. with a tag or label depending on the cloud provider # NOTE: If you change the name, all current instances having the name are getting unmanaged. name : my-app # Change it to false to completely skip all action enabled : true # Change it to false to skip the scaling dry_run : false # Not scaling down below this value min : 2 # Not scaling up above this value max : 5 # The max value of instances to be scaled down in one run max_step_down : 1 # Strategy of order to destroy instances scale_down_selection : oldest # After scaling down, wait for so long in seconds cooldown_timeout : 60 # See Policy configs policies : [] # See cloud config cloud : kind : ... launch_config : {}","title":"Common Config Skeleton"},{"location":"install/","text":"Install and base settings Install Warning Scalr is in beta. pip install scalr-ngine Settings Settings can be set either by ENV vars or by providing a .env file: Common ENV variables SCALR_LOG_LEVEL = INFO SCALR_CONFIG = ./config.yml # apply to --periodic SCALR_INTERVAL = 20 SCALR_PROMETHEUS_EXPORTER_PORT = 8000 Cloud ENV variables Cloudscale.ch API token CLOUDSCALE_API_TOKEN = <...> CloudStack API settings CLOUDSTACK_API_ENDPOINT = https://cloud.example.com/client/api CLOUDSTACK_API_KEY = <...> CLOUDSTACK_API_SECRET = <...> DigitalOcean API access token DIGITALOCEAN_ACCESS_TOKEN = <...> Exoscale API settings EXOSCALE_API_KEY = <...> EXOSCALE_API_SECRET = <...> Hetzner Cloud API token HCLOUD_API_TOKEN = <...> Vultr API key VULTR_API_KEY = <...>","title":"Install"},{"location":"install/#install-and-base-settings","text":"","title":"Install and base settings"},{"location":"install/#install","text":"Warning Scalr is in beta. pip install scalr-ngine","title":"Install"},{"location":"install/#settings","text":"Settings can be set either by ENV vars or by providing a .env file:","title":"Settings"},{"location":"install/#common-env-variables","text":"SCALR_LOG_LEVEL = INFO SCALR_CONFIG = ./config.yml # apply to --periodic SCALR_INTERVAL = 20 SCALR_PROMETHEUS_EXPORTER_PORT = 8000","title":"Common ENV variables"},{"location":"install/#cloud-env-variables","text":"","title":"Cloud ENV variables"},{"location":"install/#cloudscalech-api-token","text":"CLOUDSCALE_API_TOKEN = <...>","title":"Cloudscale.ch API token"},{"location":"install/#cloudstack-api-settings","text":"CLOUDSTACK_API_ENDPOINT = https://cloud.example.com/client/api CLOUDSTACK_API_KEY = <...> CLOUDSTACK_API_SECRET = <...>","title":"CloudStack API settings"},{"location":"install/#digitalocean-api-access-token","text":"DIGITALOCEAN_ACCESS_TOKEN = <...>","title":"DigitalOcean API access token"},{"location":"install/#exoscale-api-settings","text":"EXOSCALE_API_KEY = <...> EXOSCALE_API_SECRET = <...>","title":"Exoscale API settings"},{"location":"install/#hetzner-cloud-api-token","text":"HCLOUD_API_TOKEN = <...>","title":"Hetzner Cloud API token"},{"location":"install/#vultr-api-key","text":"VULTR_API_KEY = <...>","title":"Vultr API key"},{"location":"policy_configs/","text":"Policy Configs Policies define if and how much to scale. Metric Target The target in is the metric we want to reach. A source metric returned higher than this target will result in scaling up, a lower to scaling down. Example Given a target of 5, a source metric returned of 10 will results in a scaling factor 2.0. With 2 instances already running, a factor 2 will scale to 4 instances (2 x 2.0), except the max allow instances is lower than 4. Prometheus Policy Query a Prometheus endpoint. policy : - name : CPU avg load < 60% target : 60 source : prometheus config : url : http://prometheus.example.com:9090 query : '100 - (avg by (job) (rate(node_cpu_seconds_total{mode=\"idle\", instance=~\"cluster-node.*\"}[10m])) * 100)' Web Policy Query a web endpoint. A JSON return {\"metric\": <int>} is expected in this case. policy : - name : get metric from web source : web query : http://localhost:8000/target.json config : # Optional headers headers : Authorization : Bearer xyz # Optional default key 'data' key : metric target : 5 Random Policy For testing purpose, random metric to get some action. policy : - name : get random nonsense source : random target : 3 config : start : 1 stop : 10","title":"Policy Configs"},{"location":"policy_configs/#policy-configs","text":"Policies define if and how much to scale.","title":"Policy Configs"},{"location":"policy_configs/#metric-target","text":"The target in is the metric we want to reach. A source metric returned higher than this target will result in scaling up, a lower to scaling down. Example Given a target of 5, a source metric returned of 10 will results in a scaling factor 2.0. With 2 instances already running, a factor 2 will scale to 4 instances (2 x 2.0), except the max allow instances is lower than 4.","title":"Metric Target"},{"location":"policy_configs/#prometheus-policy","text":"Query a Prometheus endpoint. policy : - name : CPU avg load < 60% target : 60 source : prometheus config : url : http://prometheus.example.com:9090 query : '100 - (avg by (job) (rate(node_cpu_seconds_total{mode=\"idle\", instance=~\"cluster-node.*\"}[10m])) * 100)'","title":"Prometheus Policy"},{"location":"policy_configs/#web-policy","text":"Query a web endpoint. A JSON return {\"metric\": <int>} is expected in this case. policy : - name : get metric from web source : web query : http://localhost:8000/target.json config : # Optional headers headers : Authorization : Bearer xyz # Optional default key 'data' key : metric target : 5","title":"Web Policy"},{"location":"policy_configs/#random-policy","text":"For testing purpose, random metric to get some action. policy : - name : get random nonsense source : random target : 3 config : start : 1 stop : 10","title":"Random Policy"},{"location":"running/","text":"Running Start Scalr As \"one shot\" meant to be used as cron job execution: Note One shot execution does not provide Prometheus metrics. scalr-ngine As daemon: export SCALR_INTERVAL = 20 scalr-ngine --periodic Docker We provide docker images as registry.gitlab.com/ngine/docker-images/scalr:latest . A minimal docker compose file would look like: --- version : \"3.9\" services : scalr : image : registry.gitlab.com/ngine/docker-images/scalr:latest ports : - \"8000:8000\" command : --periodic environment : - SCALR_INTERVAL=60 - SCALR_LOG_LEVEL=INFO - SCALR_CONFIG=/app/config.yml - SCALR_PROMETHEUS_EXPORTER_PORT=8000 - VULTR_API_KEY=... volumes : - \"./config.yml:/app/config.yml:ro\" Monitoring Hint Exporter port can be changed SCALR_PROMETHEUS_EXPORTER_PORT . Default is 8000. Scalr running in --periodic exports Prometheus metrics, such as: # HELP python_gc_objects_collected_total Objects collected during gc # TYPE python_gc_objects_collected_total counter python_gc_objects_collected_total{generation=\"0\"} 37145.0 python_gc_objects_collected_total{generation=\"1\"} 6512.0 python_gc_objects_collected_total{generation=\"2\"} 687.0 # HELP python_gc_objects_uncollectable_total Uncollectable object found during GC # TYPE python_gc_objects_uncollectable_total counter python_gc_objects_uncollectable_total{generation=\"0\"} 0.0 python_gc_objects_uncollectable_total{generation=\"1\"} 0.0 python_gc_objects_uncollectable_total{generation=\"2\"} 0.0 # HELP python_gc_collections_total Number of times this generation was collected # TYPE python_gc_collections_total counter python_gc_collections_total{generation=\"0\"} 234.0 python_gc_collections_total{generation=\"1\"} 21.0 python_gc_collections_total{generation=\"2\"} 1.0 # HELP python_info Python platform information # TYPE python_info gauge python_info{implementation=\"CPython\",major=\"3\",minor=\"8\",patchlevel=\"10\",version=\"3.8.10\"} 1.0 # HELP process_virtual_memory_bytes Virtual memory size in bytes. # TYPE process_virtual_memory_bytes gauge process_virtual_memory_bytes 6.71674368e+08 # HELP process_resident_memory_bytes Resident memory size in bytes. # TYPE process_resident_memory_bytes gauge process_resident_memory_bytes 8.3685376e+07 # HELP process_start_time_seconds Start time of the process since unix epoch in seconds. # TYPE process_start_time_seconds gauge process_start_time_seconds 1.64899542198e+09 # HELP process_cpu_seconds_total Total user and system CPU time spent in seconds. # TYPE process_cpu_seconds_total counter process_cpu_seconds_total 157.28 # HELP process_open_fds Number of open file descriptors. # TYPE process_open_fds gauge process_open_fds 32.0 # HELP process_max_fds Maximum number of open file descriptors. # TYPE process_max_fds gauge process_max_fds 8192.0 # HELP scalr_min Min amount of resources # TYPE scalr_min gauge scalr_min 1.0 # HELP scalr_max Max amount of resources # TYPE scalr_max gauge scalr_max 5.0 # HELP scalr_factor Calculated factor of policies # TYPE scalr_factor gauge scalr_factor 5.0 # HELP scalr_desired Desired amount of resources # TYPE scalr_desired gauge scalr_desired 5.0 # HELP scalr_current Current amount of resources # TYPE scalr_current gauge scalr_current 5.0 # HELP scalr_max_step_down Max step for scaling down # TYPE scalr_max_step_down gauge scalr_max_step_down 1.0 # HELP scalr_cooldown_timeout Timeout in seconds after scaling actions # TYPE scalr_cooldown_timeout gauge scalr_cooldown_timeout 300.0 # HELP scalr_dry_run Dry run mode # TYPE scalr_dry_run gauge scalr_dry_run{scalr_dry_run=\"on\"} 0.0 scalr_dry_run{scalr_dry_run=\"off\"} 1.0 # HELP scalr_enabled Scaling enabled # TYPE scalr_enabled gauge scalr_enabled{scalr_enabled=\"yes\"} 1.0 scalr_enabled{scalr_enabled=\"no\"} 0.0 Prometheus Scrape Config scrape_configs : - job_name : scalr metrics_path : / scrape_interval : 5s static_configs : - targets : - scalr-app:8000 Graphana Dashboard A simple dashboard for scalr can be found on Github","title":"Run"},{"location":"running/#running","text":"","title":"Running"},{"location":"running/#start-scalr","text":"As \"one shot\" meant to be used as cron job execution: Note One shot execution does not provide Prometheus metrics. scalr-ngine As daemon: export SCALR_INTERVAL = 20 scalr-ngine --periodic","title":"Start Scalr"},{"location":"running/#docker","text":"We provide docker images as registry.gitlab.com/ngine/docker-images/scalr:latest . A minimal docker compose file would look like: --- version : \"3.9\" services : scalr : image : registry.gitlab.com/ngine/docker-images/scalr:latest ports : - \"8000:8000\" command : --periodic environment : - SCALR_INTERVAL=60 - SCALR_LOG_LEVEL=INFO - SCALR_CONFIG=/app/config.yml - SCALR_PROMETHEUS_EXPORTER_PORT=8000 - VULTR_API_KEY=... volumes : - \"./config.yml:/app/config.yml:ro\"","title":"Docker"},{"location":"running/#monitoring","text":"Hint Exporter port can be changed SCALR_PROMETHEUS_EXPORTER_PORT . Default is 8000. Scalr running in --periodic exports Prometheus metrics, such as: # HELP python_gc_objects_collected_total Objects collected during gc # TYPE python_gc_objects_collected_total counter python_gc_objects_collected_total{generation=\"0\"} 37145.0 python_gc_objects_collected_total{generation=\"1\"} 6512.0 python_gc_objects_collected_total{generation=\"2\"} 687.0 # HELP python_gc_objects_uncollectable_total Uncollectable object found during GC # TYPE python_gc_objects_uncollectable_total counter python_gc_objects_uncollectable_total{generation=\"0\"} 0.0 python_gc_objects_uncollectable_total{generation=\"1\"} 0.0 python_gc_objects_uncollectable_total{generation=\"2\"} 0.0 # HELP python_gc_collections_total Number of times this generation was collected # TYPE python_gc_collections_total counter python_gc_collections_total{generation=\"0\"} 234.0 python_gc_collections_total{generation=\"1\"} 21.0 python_gc_collections_total{generation=\"2\"} 1.0 # HELP python_info Python platform information # TYPE python_info gauge python_info{implementation=\"CPython\",major=\"3\",minor=\"8\",patchlevel=\"10\",version=\"3.8.10\"} 1.0 # HELP process_virtual_memory_bytes Virtual memory size in bytes. # TYPE process_virtual_memory_bytes gauge process_virtual_memory_bytes 6.71674368e+08 # HELP process_resident_memory_bytes Resident memory size in bytes. # TYPE process_resident_memory_bytes gauge process_resident_memory_bytes 8.3685376e+07 # HELP process_start_time_seconds Start time of the process since unix epoch in seconds. # TYPE process_start_time_seconds gauge process_start_time_seconds 1.64899542198e+09 # HELP process_cpu_seconds_total Total user and system CPU time spent in seconds. # TYPE process_cpu_seconds_total counter process_cpu_seconds_total 157.28 # HELP process_open_fds Number of open file descriptors. # TYPE process_open_fds gauge process_open_fds 32.0 # HELP process_max_fds Maximum number of open file descriptors. # TYPE process_max_fds gauge process_max_fds 8192.0 # HELP scalr_min Min amount of resources # TYPE scalr_min gauge scalr_min 1.0 # HELP scalr_max Max amount of resources # TYPE scalr_max gauge scalr_max 5.0 # HELP scalr_factor Calculated factor of policies # TYPE scalr_factor gauge scalr_factor 5.0 # HELP scalr_desired Desired amount of resources # TYPE scalr_desired gauge scalr_desired 5.0 # HELP scalr_current Current amount of resources # TYPE scalr_current gauge scalr_current 5.0 # HELP scalr_max_step_down Max step for scaling down # TYPE scalr_max_step_down gauge scalr_max_step_down 1.0 # HELP scalr_cooldown_timeout Timeout in seconds after scaling actions # TYPE scalr_cooldown_timeout gauge scalr_cooldown_timeout 300.0 # HELP scalr_dry_run Dry run mode # TYPE scalr_dry_run gauge scalr_dry_run{scalr_dry_run=\"on\"} 0.0 scalr_dry_run{scalr_dry_run=\"off\"} 1.0 # HELP scalr_enabled Scaling enabled # TYPE scalr_enabled gauge scalr_enabled{scalr_enabled=\"yes\"} 1.0 scalr_enabled{scalr_enabled=\"no\"} 0.0","title":"Monitoring"},{"location":"running/#prometheus-scrape-config","text":"scrape_configs : - job_name : scalr metrics_path : / scrape_interval : 5s static_configs : - targets : - scalr-app:8000","title":"Prometheus Scrape Config"},{"location":"running/#graphana-dashboard","text":"A simple dashboard for scalr can be found on Github","title":"Graphana Dashboard"}]}